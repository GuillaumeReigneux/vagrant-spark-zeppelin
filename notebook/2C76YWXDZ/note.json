{
  "paragraphs": [
    {
      "text": "%md\n\n# Binary Classification Algorithms with Pipelines API\n\nName(s): _REIGNEUX Guillaume_\nClass: _BIBD_\n\n\n\u003chr\u003e\n\nDans ce notebook, l\u0027objectif est de tester les algo de classification binaire disponibles dans l\u0027API ML Pipelines sur le jeu de donnée \"Adult\"\n\n**[LIEN VERS LA DOCUMENTATION](http://spark.apache.org/docs/2.0.1/ml-guide.html)**.\n\n\nOn est donc sur de la **prédiction**.\n\n__Objectif :__\n- Commit régulièrement son travail.\n- Complèter l\u0027ensemble de l\u0027analyse.(Evalution de la plus value de la prédiction)\n- Bien penser à commenter pour que Fanilo puisse suivre le chemin de pensé.\n- Si l\u0027envie me prend, je peux partir sur des pistes de reflexion différente de celle qui sont proposés à travers les questions.\n\n\u003chr\u003e\n\n####Table des matières :\n\n* Présentation du jeu de donnée\n* Load Data\n* Descriptive analysis\n* Data Preprocessing\n* Creation of models\n* Conclusion\n\n\u003chr\u003e\n",
      "dateUpdated": "Mar 6, 2017 7:45:56 AM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "enabled": true,
        "editorMode": "ace/mode/markdown",
        "editorHide": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1486110006257_-279747651",
      "id": "20170203-082006_1849162249",
      "result": {
        "code": "SUCCESS",
        "type": "HTML",
        "msg": "\u003ch1\u003eBinary Classification Algorithms with Pipelines API\u003c/h1\u003e\n\u003cp\u003eName(s): \u003cem\u003eREIGNEUX Guillaume\u003c/em\u003e\n\u003cbr  /\u003eClass: \u003cem\u003eBIBD\u003c/em\u003e\u003c/p\u003e\n\u003chr\u003e\n\u003cp\u003eDans ce notebook, l\u0027objectif est de tester les algo de classification binaire disponibles dans l\u0027API ML Pipelines sur le jeu de donnée \u0026ldquo;Adult\u0026rdquo;\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e\u003ca href\u003d\"http://spark.apache.org/docs/2.0.1/ml-guide.html\"\u003eLIEN VERS LA DOCUMENTATION\u003c/a\u003e\u003c/strong\u003e.\u003c/p\u003e\n\u003cp\u003eOn est donc sur de la \u003cstrong\u003eprédiction\u003c/strong\u003e.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eObjectif :\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eCommit régulièrement son travail.\u003c/li\u003e\n\u003cli\u003eComplèter l\u0027ensemble de l\u0027analyse.(Evalution de la plus value de la prédiction)\u003c/li\u003e\n\u003cli\u003eBien penser à commenter pour que Fanilo puisse suivre le chemin de pensé.\u003c/li\u003e\n\u003cli\u003eSi l\u0027envie me prend, je peux partir sur des pistes de reflexion différente de celle qui sont proposés à travers les questions.\u003c/li\u003e\n\u003c/ul\u003e\n\u003chr\u003e\n\u003ch4\u003eTable des matières :\u003c/h4\u003e\n\u003cul\u003e\n\u003cli\u003ePrésentation du jeu de donnée\u003c/li\u003e\n\u003cli\u003eLoad Data\u003c/li\u003e\n\u003cli\u003eDescriptive analysis\u003c/li\u003e\n\u003cli\u003eData Preprocessing\u003c/li\u003e\n\u003cli\u003eCreation of models\u003c/li\u003e\n\u003cli\u003eConclusion\u003c/li\u003e\n\u003c/ul\u003e\n\u003chr\u003e\n"
      },
      "dateCreated": "Feb 3, 2017 8:20:06 AM",
      "dateStarted": "Mar 6, 2017 7:45:51 AM",
      "dateFinished": "Mar 6, 2017 7:45:51 AM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\n\n## 1) Jeu de donnée \"Adult\"\n\n**UCI Machine Learning Repository :**\n[Lien vers les données](https://archive.ics.uci.edu/ml/datasets/Adult)\n\n** Information général **\n\n48842 individus\n14 variables :\n- age: continuous\n- workclass: Private, Self-emp-not-inc, Self-emp-inc, Federal-gov, Local-gov, State-gov, Without-pay, Never-worked\n- fnlwgt: continuous\n- education: Bachelors, Some-college, 11th, HS-grad, Prof-school, Assoc-acdm, Assoc-voc...\n- education-num: continuous\n- marital-status: Married-civ-spouse, Divorced, Never-married, Separated, Widowed, Married-spouse-absent...\n- occupation: Tech-support, Craft-repair, Other-service, Sales, Exec-managerial, Prof-specialty, Handlers-cleaners...\n- relationship: Wife, Own-child, Husband, Not-in-family, Other-relative, Unmarried\n- race: White, Asian-Pac-Islander, Amer-Indian-Eskimo, Other, Black\n- sex: Female, Male. \n- capital-gain: continuous\n- capital-loss: continuous\n- hours-per-week: continuous\n- native-country: United-States, Cambodia, England, Puerto-Rico, Canada, Germany...\n\n**Variable à prédire :**\n Est ce que la variable \"income\" est à \u003c\u003d50k ou \u003e50k\n\nLe jeu de donnée est normalement propre.\n\n",
      "dateUpdated": "Mar 6, 2017 7:45:18 AM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "enabled": true,
        "editorHide": true,
        "editorMode": "ace/mode/markdown"
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1486110092601_361345828",
      "id": "20170203-082132_1615989350",
      "result": {
        "code": "SUCCESS",
        "type": "HTML",
        "msg": "\u003ch2\u003e1) Jeu de donnée \u0026ldquo;Adult\u0026rdquo;\u003c/h2\u003e\n\u003cp\u003e\u003cstrong\u003eUCI Machine Learning Repository :\u003c/strong\u003e\n\u003cbr  /\u003e\u003ca href\u003d\"https://archive.ics.uci.edu/ml/datasets/Adult\"\u003eLien vers les données\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e\u003cem\u003e\u003c/em\u003e Information général \u003cem\u003e\u003c/em\u003e\u003c/p\u003e\n\u003cp\u003e48842 individus\n\u003cbr  /\u003e14 variables :\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eage: continuous\u003c/li\u003e\n\u003cli\u003eworkclass: Private, Self-emp-not-inc, Self-emp-inc, Federal-gov, Local-gov, State-gov, Without-pay, Never-worked\u003c/li\u003e\n\u003cli\u003efnlwgt: continuous\u003c/li\u003e\n\u003cli\u003eeducation: Bachelors, Some-college, 11th, HS-grad, Prof-school, Assoc-acdm, Assoc-voc\u0026hellip;\u003c/li\u003e\n\u003cli\u003eeducation-num: continuous\u003c/li\u003e\n\u003cli\u003emarital-status: Married-civ-spouse, Divorced, Never-married, Separated, Widowed, Married-spouse-absent\u0026hellip;\u003c/li\u003e\n\u003cli\u003eoccupation: Tech-support, Craft-repair, Other-service, Sales, Exec-managerial, Prof-specialty, Handlers-cleaners\u0026hellip;\u003c/li\u003e\n\u003cli\u003erelationship: Wife, Own-child, Husband, Not-in-family, Other-relative, Unmarried\u003c/li\u003e\n\u003cli\u003erace: White, Asian-Pac-Islander, Amer-Indian-Eskimo, Other, Black\u003c/li\u003e\n\u003cli\u003esex: Female, Male.\u003c/li\u003e\n\u003cli\u003ecapital-gain: continuous\u003c/li\u003e\n\u003cli\u003ecapital-loss: continuous\u003c/li\u003e\n\u003cli\u003ehours-per-week: continuous\u003c/li\u003e\n\u003cli\u003enative-country: United-States, Cambodia, England, Puerto-Rico, Canada, Germany\u0026hellip;\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003eVariable à prédire :\u003c/strong\u003e\n\u003cbr  /\u003eEst ce que la variable \u0026ldquo;income\u0026rdquo; est à \u003c\u003d50k ou \u003e50k\u003c/p\u003e\n\u003cp\u003eLe jeu de donnée est normalement propre.\u003c/p\u003e\n"
      },
      "dateCreated": "Feb 3, 2017 8:21:32 AM",
      "dateStarted": "Mar 6, 2017 7:42:46 AM",
      "dateFinished": "Mar 6, 2017 7:42:46 AM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\n\n## 2) Chargement des données\n\nI have downloaded adult.data from the [UCI Machine Learning Repository](https://archive.ics.uci.edu/ml/datasets/Adult) and put it into the `data/` folder of your project.\n\nThe following cells will do the necessary to load the data into a DataFrame.",
      "dateUpdated": "Mar 7, 2017 12:44:04 PM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "enabled": true,
        "editorMode": "ace/mode/markdown",
        "editorHide": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1486110944465_2111795148",
      "id": "20170203-083544_2073974112",
      "result": {
        "code": "SUCCESS",
        "type": "HTML",
        "msg": "\u003ch2\u003e2) Chargement des données\u003c/h2\u003e\n\u003cp\u003eI have downloaded adult.data from the \u003ca href\u003d\"https://archive.ics.uci.edu/ml/datasets/Adult\"\u003eUCI Machine Learning Repository\u003c/a\u003e and put it into the \u003ccode\u003edata/\u003c/code\u003e folder of your project.\u003c/p\u003e\n\u003cp\u003eThe following cells will do the necessary to load the data into a DataFrame.\u003c/p\u003e\n"
      },
      "dateCreated": "Feb 3, 2017 8:35:44 AM",
      "dateStarted": "Mar 7, 2017 12:44:03 PM",
      "dateFinished": "Mar 7, 2017 12:44:03 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "title": "Load data (run the cell)",
      "text": "import org.apache.spark.sql.types.{StringType, DoubleType, StructType, StructField}\n\nval schema \u003d StructType(Seq(\n    StructField(\"age\", DoubleType),\n    StructField(\"workclass\", StringType),\n    StructField(\"fnlwgt\", DoubleType),\n    StructField(\"education\", StringType),\n    StructField(\"education_num\", DoubleType),\n    StructField(\"marital_status\", StringType),\n    StructField(\"occupation\", StringType),\n    StructField(\"relationship\", StringType),\n    StructField(\"race\", StringType),\n    StructField(\"sex\", StringType),\n    StructField(\"capital_gain\", DoubleType),\n    StructField(\"capital_loss\", DoubleType),\n    StructField(\"hours_per_week\", DoubleType),\n    StructField(\"native_country\", StringType),\n    StructField(\"income\", StringType)\n    ))\n\ncase class Adult(\n    age: Double, \n    workclass: String, \n    fnlwgt: Double, \n    education: String, \n    education_num: Double, \n    marital_status: String, \n    occupation: String, \n    relationship: String, \n    race: String, \n    sex: String, \n    capital_gain: Double, \n    capital_loss: Double, \n    hours_per_week: Double, \n    native_country: String, \n    income: String\n    )\n    \nval dataset \u003d spark.read.schema(schema).csv(\"/opt/dataset/adult.data.csv\").as[Adult]\ndataset.registerTempTable(\"dataset\")  // register it so we can use it inside %sql interpreter",
      "dateUpdated": "Mar 6, 2017 7:44:45 AM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "enabled": true,
        "editorMode": "ace/mode/scala",
        "title": true,
        "editorHide": true,
        "tableHide": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1486111413898_843508411",
      "id": "20170203-084333_2125853520",
      "result": {
        "code": "SUCCESS",
        "type": "TEXT",
        "msg": "\nimport org.apache.spark.sql.types.{StringType, DoubleType, StructType, StructField}\n\nschema: org.apache.spark.sql.types.StructType \u003d StructType(StructField(age,DoubleType,true), StructField(workclass,StringType,true), StructField(fnlwgt,DoubleType,true), StructField(education,StringType,true), StructField(education_num,DoubleType,true), StructField(marital_status,StringType,true), StructField(occupation,StringType,true), StructField(relationship,StringType,true), StructField(race,StringType,true), StructField(sex,StringType,true), StructField(capital_gain,DoubleType,true), StructField(capital_loss,DoubleType,true), StructField(hours_per_week,DoubleType,true), StructField(native_country,StringType,true), StructField(income,StringType,true))\n\ndefined class Adult\n\ndataset: org.apache.spark.sql.Dataset[Adult] \u003d [age: double, workclass: string ... 13 more fields]\n\nwarning: there was one deprecation warning; re-run with -deprecation for details\n"
      },
      "dateCreated": "Feb 3, 2017 8:43:33 AM",
      "dateStarted": "Mar 6, 2017 7:43:14 AM",
      "dateFinished": "Mar 6, 2017 7:43:25 AM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "dataset.printSchema()",
      "dateUpdated": "Mar 6, 2017 7:44:50 AM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "enabled": true,
        "editorMode": "ace/mode/scala",
        "editorHide": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1486388735078_22636095",
      "id": "20170206-134535_81642944",
      "result": {
        "code": "SUCCESS",
        "type": "TEXT",
        "msg": "root\n |-- age: double (nullable \u003d true)\n |-- workclass: string (nullable \u003d true)\n |-- fnlwgt: double (nullable \u003d true)\n |-- education: string (nullable \u003d true)\n |-- education_num: double (nullable \u003d true)\n |-- marital_status: string (nullable \u003d true)\n |-- occupation: string (nullable \u003d true)\n |-- relationship: string (nullable \u003d true)\n |-- race: string (nullable \u003d true)\n |-- sex: string (nullable \u003d true)\n |-- capital_gain: double (nullable \u003d true)\n |-- capital_loss: double (nullable \u003d true)\n |-- hours_per_week: double (nullable \u003d true)\n |-- native_country: string (nullable \u003d true)\n |-- income: string (nullable \u003d true)\n\n"
      },
      "dateCreated": "Feb 6, 2017 1:45:35 AM",
      "dateStarted": "Mar 6, 2017 7:43:29 AM",
      "dateFinished": "Mar 6, 2017 7:43:31 AM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md \n\n## 3) Analyse Descriptive\n\n\u003ch4 style\u003d\"color:red;\"\u003eExercice\u003c/h4\u003e\n\nFournir un récapitulatif statistiques des données pour les variables intéressantes.\nJ\u0027ai fait le choix de faire une revue en prenant en compte directement la variable \"income\" afin de commencer à donner du sens à mon analyse (de plus cela peut potentiellement m\u0027aider à clarifier mes résultats aux moments de la prédiction).\n\n\nDeux manières de faire ceci:\n\n* Faire du requête SQL standard puis .show()\n* Utiliser l\u0027API pour obtenir des représentation graphiques.\n\n\n** Revu d\u0027intérêt pour les variables**\nage: à faire, grosse pertinence par rapport au revenu (expérience)\nworkclass: pertinent aussi\nfnlwgt: pas réussi à trouver à quoi cela correspondait\neducation: à coupler avec education_num\neducation_num: \nmarital_status: je ne vois pas trop l\u0027intérêt par rapport au revenu...\noccupation: tout comme work-class mais peut être trop brouillon ?\nrelationship: Comme le marital status je ne vois pas l\u0027intérêt\nrace: si comme j\u0027ai cru le comprendre, les individus sont tous aux USA on peut faire une recherche la dessus par rapport à une éventuelle discrimination raciale\nsex: Intéressant par rapport à l\u0027inégalité salarial entre les sexes\ncapital_gain: pas sur que ça ai une incidence sur le revenu\ncapital_loss: exactement pareil\nhours_per_week: peut être intéressant \"travailler plus pour gagner plus !\"\nnative_country: A voir avec la variable \"race\"\n\n",
      "dateUpdated": "Mar 7, 2017 12:44:16 PM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "enabled": true,
        "editorMode": "ace/mode/markdown",
        "editorHide": true,
        "tableHide": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1486112392026_-185455167",
      "id": "20170203-085952_1247149665",
      "result": {
        "code": "SUCCESS",
        "type": "HTML",
        "msg": "\u003ch2\u003e3) Analyse Descriptive\u003c/h2\u003e\n\u003ch4 style\u003d\"color:red;\"\u003eExercice\u003c/h4\u003e\n\u003cp\u003eFournir un récapitulatif statistiques des données pour les variables intéressantes.\n\u003cbr  /\u003eJ\u0027ai fait le choix de faire une revue en prenant en compte directement la variable \u0026ldquo;income\u0026rdquo; afin de commencer à donner du sens à mon analyse (de plus cela peut potentiellement m\u0027aider à clarifier mes résultats aux moments de la prédiction).\u003c/p\u003e\n\u003cp\u003eDeux manières de faire ceci:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eFaire du requête SQL standard puis .show()\u003c/li\u003e\n\u003cli\u003eUtiliser l\u0027API pour obtenir des représentation graphiques.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cem\u003e\u003c/em\u003e Revu d\u0027intérêt pour les variables**\n\u003cbr  /\u003eage: à faire, grosse pertinence par rapport au revenu (expérience)\n\u003cbr  /\u003eworkclass: pertinent aussi\n\u003cbr  /\u003efnlwgt: pas réussi à trouver à quoi cela correspondait\n\u003cbr  /\u003eeducation: à coupler avec education_num\n\u003cbr  /\u003eeducation_num:\n\u003cbr  /\u003emarital_status: je ne vois pas trop l\u0027intérêt par rapport au revenu\u0026hellip;\n\u003cbr  /\u003eoccupation: tout comme work-class mais peut être trop brouillon ?\n\u003cbr  /\u003erelationship: Comme le marital status je ne vois pas l\u0027intérêt\n\u003cbr  /\u003erace: si comme j\u0027ai cru le comprendre, les individus sont tous aux USA on peut faire une recherche la dessus par rapport à une éventuelle discrimination raciale\n\u003cbr  /\u003esex: Intéressant par rapport à l\u0027inégalité salarial entre les sexes\n\u003cbr  /\u003ecapital_gain: pas sur que ça ai une incidence sur le revenu\n\u003cbr  /\u003ecapital_loss: exactement pareil\n\u003cbr  /\u003ehours_per_week: peut être intéressant \u0026ldquo;travailler plus pour gagner plus !\u0026rdquo;\n\u003cbr  /\u003enative_country: A voir avec la variable \u0026ldquo;race\u0026rdquo;\u003c/p\u003e\n"
      },
      "dateCreated": "Feb 3, 2017 8:59:52 AM",
      "dateStarted": "Mar 7, 2017 12:44:15 PM",
      "dateFinished": "Mar 7, 2017 12:44:15 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "title": "Analyse descriptive : Moyenne d\u0027âge en fonction du salaire",
      "text": "%sql SELECT avg(age), income FROM dataset group by income ",
      "dateUpdated": "Mar 7, 2017 11:06:01 AM",
      "config": {
        "colWidth": 6.0,
        "graph": {
          "mode": "table",
          "height": 216.0,
          "optionOpen": true,
          "keys": [
            {
              "name": "avg(age)",
              "index": 0.0,
              "aggr": "sum"
            }
          ],
          "values": [
            {
              "name": "income",
              "index": 1.0,
              "aggr": "sum"
            }
          ],
          "groups": [],
          "scatter": {
            "xAxis": {
              "name": "avg(age)",
              "index": 0.0,
              "aggr": "sum"
            },
            "yAxis": {
              "name": "income",
              "index": 1.0,
              "aggr": "sum"
            }
          }
        },
        "enabled": true,
        "editorMode": "ace/mode/sql",
        "title": true,
        "editorHide": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1488831356233_-116781175",
      "id": "20170306-201556_1930241920",
      "result": {
        "code": "SUCCESS",
        "type": "TABLE",
        "msg": "avg(age)\tincome\n44.24984058155847\t \u003e50K\n36.78373786407767\t \u003c\u003d50K\n"
      },
      "dateCreated": "Mar 6, 2017 8:15:56 AM",
      "dateStarted": "Mar 6, 2017 10:04:26 AM",
      "dateFinished": "Mar 6, 2017 10:04:28 AM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "title": "Analyse descriptive : Distribution des groupes de salaire en fonction du sexe",
      "text": "%sql select sex,income, (100. * count(*) / sum(count(*)) over ()) as pourcentage\r\nfrom dataset\r\ngroup by sex, income",
      "dateUpdated": "Mar 7, 2017 10:27:01 AM",
      "config": {
        "colWidth": 6.0,
        "graph": {
          "mode": "table",
          "height": 177.0,
          "optionOpen": false,
          "keys": [
            {
              "name": "sex",
              "index": 0.0,
              "aggr": "sum"
            }
          ],
          "values": [
            {
              "name": "income",
              "index": 1.0,
              "aggr": "sum"
            }
          ],
          "groups": [],
          "scatter": {
            "yAxis": {
              "name": "income",
              "index": 1.0,
              "aggr": "sum"
            },
            "xAxis": {
              "name": "sex",
              "index": 0.0,
              "aggr": "sum"
            }
          }
        },
        "enabled": true,
        "editorMode": "ace/mode/sql",
        "title": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1488838037684_-1849777306",
      "id": "20170306-220717_134276265",
      "result": {
        "code": "SUCCESS",
        "type": "TABLE",
        "msg": "sex\tincome\tpourcentage\n Male\t \u003c\u003d50K\t46.4604895427044623937\n Male\t \u003e50K\t20.4600595804797149965\n Female\t \u003e50K\t3.6208961641227235036\n Female\t \u003c\u003d50K\t29.4585547126930991063\n"
      },
      "dateCreated": "Mar 6, 2017 10:07:17 AM",
      "dateStarted": "Mar 7, 2017 10:22:52 AM",
      "dateFinished": "Mar 7, 2017 10:22:54 AM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "title": "Analyse descriptive : Moyenne d\u0027âge en fonction du salaire",
      "text": "%md\n\nOn commence tout d\u0027abord par observer la moyenne d\u0027âge en fonction de la tranche de salaire.\nEn effet on part du principe que notre salaire augmente au fur et à mesure que nous accumulons de l\u0027expérience.\nCela se vérifie ici avec **8 ans** d\u0027écart environ pour la moyenne d\u0027âge des salaires au dessus de 50k et ceux en dessous de 50k",
      "dateUpdated": "Mar 7, 2017 10:45:10 AM",
      "config": {
        "colWidth": 6.0,
        "graph": {
          "mode": "table",
          "height": 119.0,
          "optionOpen": false,
          "keys": [
            {
              "name": "sex",
              "index": 0.0,
              "aggr": "sum"
            }
          ],
          "values": [
            {
              "name": "count(income)",
              "index": 1.0,
              "aggr": "sum"
            }
          ],
          "groups": [],
          "scatter": {
            "xAxis": {
              "name": "sex",
              "index": 0.0,
              "aggr": "sum"
            }
          }
        },
        "enabled": true,
        "editorMode": "ace/mode/markdown",
        "title": true,
        "editorHide": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1488838071596_1258871213",
      "id": "20170306-220751_2033404787",
      "result": {
        "code": "SUCCESS",
        "type": "HTML",
        "msg": "\u003cp\u003eOn commence tout d\u0027abord par observer la moyenne d\u0027âge en fonction de la tranche de salaire.\n\u003cbr  /\u003eEn effet on part du principe que notre salaire augmente au fur et à mesure que nous accumulons de l\u0027expérience.\n\u003cbr  /\u003eCela se vérifie ici avec \u003cstrong\u003e8 ans\u003c/strong\u003e d\u0027écart environ pour la moyenne d\u0027âge des salaires au dessus de 50k et ceux en dessous de 50k\u003c/p\u003e\n"
      },
      "dateCreated": "Mar 6, 2017 10:07:51 AM",
      "dateStarted": "Mar 7, 2017 10:31:17 AM",
      "dateFinished": "Mar 7, 2017 10:31:17 AM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "title": "Analyse descriptive : Distribution des groupes de salaire en fonction du sexe",
      "text": "%md\n\nOn s\u0027attaque ensuite à une idée qui voudrait que les hommes soient mieux payés que les femmes pour le même travail.\n\nLe tableau ci dessus nous montre tout d\u0027abord que nos données contiennent beaucoup plus d\u0027homme (46+20\u003d\u003e**64% d\u0027homme** contre **34% de femme** )\n\nSi on part sur une base de 1000 individus on a donc :\n\n1000 * 0,46 \u003d 460 hommes avec un salaire \u003e\u003d50k\n1000 * 0,20 \u003d 200 hommes avec un salaire \u003c50k\n\n1000 * 0,29 \u003d 290 femmes avec un salaire \u003e\u003d50k\n1000 * 0,036 \u003d 36 femmes avec un salaire \u003c50k\n\nRamené au sexe cela nous donne :\n460 / (460+200) \u003d 74 % des hommes avec un salaire \u003e\u003d50k sur l\u0027ensemble des hommes\n290 / (290+36) \u003d 88 % des femmes avec un salaire \u003e\u003d50k sur l\u0027ensemble des femmes\n\nBien entendu, cette analyse est à prendre avec du recul (il faudrait comparer individu par individu pour pouvoir avancer des résultats pertinent, ici cela se peut très bien que les femmes soient moins bien payé que les hommes à poste équivalent, mais que l\u0027échantillon contienne plus de femme à poste à haut salaire ",
      "dateUpdated": "Mar 7, 2017 10:45:02 AM",
      "config": {
        "colWidth": 6.0,
        "graph": {
          "mode": "table",
          "height": 86.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "enabled": true,
        "title": true,
        "editorMode": "ace/mode/markdown",
        "editorHide": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1488882351050_2054595788",
      "id": "20170307-102551_265119461",
      "result": {
        "code": "SUCCESS",
        "type": "HTML",
        "msg": "\u003cp\u003eOn s\u0027attaque ensuite à une idée qui voudrait que les hommes soient mieux payés que les femmes pour le même travail.\u003c/p\u003e\n\u003cp\u003eLe tableau ci dessus nous montre tout d\u0027abord que nos données contiennent beaucoup plus d\u0027homme (46+20\u003d\u003e\u003cstrong\u003e64% d\u0027homme\u003c/strong\u003e contre \u003cstrong\u003e34% de femme\u003c/strong\u003e )\u003c/p\u003e\n\u003cp\u003eSi on part sur une base de 1000 individus on a donc :\u003c/p\u003e\n\u003cp\u003e1000 * 0,46 \u003d 460 hommes avec un salaire \u003e\u003d50k\n\u003cbr  /\u003e1000 * 0,20 \u003d 200 hommes avec un salaire \u0026lt;50k\u003c/p\u003e\n\u003cp\u003e1000 * 0,29 \u003d 290 femmes avec un salaire \u003e\u003d50k\n\u003cbr  /\u003e1000 * 0,036 \u003d 36 femmes avec un salaire \u0026lt;50k\u003c/p\u003e\n\u003cp\u003eRamené au sexe cela nous donne :\n\u003cbr  /\u003e460 / (460+200) \u003d 74 % des hommes avec un salaire \u003e\u003d50k sur l\u0027ensemble des hommes\n\u003cbr  /\u003e290 / (290+36) \u003d 88 % des femmes avec un salaire \u003e\u003d50k sur l\u0027ensemble des femmes\u003c/p\u003e\n\u003cp\u003eBien entendu, cette analyse est à prendre avec du recul (il faudrait comparer individu par individu pour pouvoir avancer des résultats pertinent, ici cela se peut très bien que les femmes soient moins bien payé que les hommes à poste équivalent, mais que l\u0027échantillon contienne plus de femme à poste à haut salaire\u003c/p\u003e\n"
      },
      "dateCreated": "Mar 7, 2017 10:25:51 AM",
      "dateStarted": "Mar 7, 2017 10:44:56 AM",
      "dateFinished": "Mar 7, 2017 10:44:56 AM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "title": "Analyse descriptive : Répartition des individus en fonction du type de salaire et du niveau d\u0027éducation",
      "text": "%sql\r\n\r\nselect education_num,income, (100. * count(*) / sum(count(*)) over ()) as pourcentage\r\nfrom dataset\r\ngroup by education_num, income\r\norder by education_num DESC",
      "dateUpdated": "Mar 7, 2017 11:12:47 AM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "multiBarChart",
          "height": 200.0,
          "optionOpen": false,
          "keys": [
            {
              "name": "education_num",
              "index": 0.0,
              "aggr": "sum"
            }
          ],
          "values": [
            {
              "name": "pourcentage",
              "index": 2.0,
              "aggr": "sum"
            }
          ],
          "groups": [
            {
              "name": "income",
              "index": 1.0,
              "aggr": "sum"
            }
          ],
          "scatter": {
            "xAxis": {
              "name": "education_num",
              "index": 0.0,
              "aggr": "sum"
            },
            "yAxis": {
              "name": "income",
              "index": 1.0,
              "aggr": "sum"
            }
          }
        },
        "enabled": true,
        "editorMode": "ace/mode/sql",
        "title": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1488883532846_-898422063",
      "id": "20170307-104532_218080189",
      "result": {
        "code": "SUCCESS",
        "type": "TABLE",
        "msg": "education_num\tincome\tpourcentage\n16.0\t \u003e50K\t0.9397745769478824360\n16.0\t \u003c\u003d50K\t0.3286139860569392832\n15.0\t \u003e50K\t1.2991001504867786616\n15.0\t \u003c\u003d50K\t0.4698872884739412180\n14.0\t \u003c\u003d50K\t2.3463652836215103959\n14.0\t \u003e50K\t2.9452412395196707718\n13.0\t \u003e50K\t6.8210435797426368969\n13.0\t \u003c\u003d50K\t9.6250115168453057339\n12.0\t \u003c\u003d50K\t2.4630693160529467768\n12.0\t \u003e50K\t0.8138570682718589724\n11.0\t \u003e50K\t1.1086883080986456190\n11.0\t \u003c\u003d50K\t3.1356530819078038144\n10.0\t \u003c\u003d50K\t18.1321212493473787660\n10.0\t \u003e50K\t4.2596971837474279045\n9.0\t \u003c\u003d50K\t27.1060471115751973219\n9.0\t \u003e50K\t5.1441909032277878444\n8.0\t \u003c\u003d50K\t1.2284634992782776942\n8.0\t \u003e50K\t0.1013482386904579098\n7.0\t \u003c\u003d50K\t3.4243420042381990725\n7.0\t \u003e50K\t0.1842695248917416541\n6.0\t \u003c\u003d50K\t2.6749792696784496791\n6.0\t \u003e50K\t0.1904118423881330426\n5.0\t \u003c\u003d50K\t1.4956543103713030927\n5.0\t \u003e50K\t0.0829212862012837444\n4.0\t \u003e50K\t0.1228463499278277694\n4.0\t \u003c\u003d50K\t1.8611222014065907067\n3.0\t \u003e50K\t0.0491385399711311078\n3.0\t \u003c\u003d50K\t0.9735573231780350726\n2.0\t \u003e50K\t0.0184269524891741654\n2.0\t \u003c\u003d50K\t0.4975277172077024661\n1.0\t \u003c\u003d50K\t0.1566290961579804060\n"
      },
      "dateCreated": "Mar 7, 2017 10:45:32 AM",
      "dateStarted": "Mar 7, 2017 11:08:59 AM",
      "dateFinished": "Mar 7, 2017 11:09:02 AM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "title": "Analyse descriptive : Explication",
      "text": "%md\n\nL\u0027histogramme ci-dessus nous fourni plusieurs informations intéressante.\n\nEn effet, il nous permet tout d\u0027abord d\u0027obtenir la répartition du niveau d\u0027éducation (on voit bien que pour **9, 10 et 13** les pourcentages sont plus important)\nAinsi nous avons 27+5+18+4+9+6\u003d 69% environ de nos individus concentrés sur trois niveau d\u0027éducations.\n\nLe deuxième fait intéressant ici est de voir que le niveau d\u0027éducation joue visiblement sur l\u0027appartenance à un type de salaire.\nEn effet, seulement les individus dont le **niveau d\u0027éducation est supérieur ou égal à 14** sont **majoritairement** avec des **salaire supérieur à 50k**.\n\nDésormais on va faire le comparatif",
      "dateUpdated": "Mar 7, 2017 11:51:44 AM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "enabled": true,
        "title": true,
        "editorMode": "ace/mode/markdown",
        "editorHide": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1488883578286_1857165408",
      "id": "20170307-104618_1355105216",
      "result": {
        "code": "SUCCESS",
        "type": "HTML",
        "msg": "\u003cp\u003eL\u0027histogramme ci-dessus nous fourni plusieurs informations intéressante.\u003c/p\u003e\n\u003cp\u003eEn effet, il nous permet tout d\u0027abord d\u0027obtenir la répartition du niveau d\u0027éducation (on voit bien que pour \u003cstrong\u003e9, 10 et 13\u003c/strong\u003e les pourcentages sont plus important)\n\u003cbr  /\u003eAinsi nous avons 27+5+18+4+9+6\u003d 69% environ de nos individus concentrés sur trois niveau d\u0027éducations.\u003c/p\u003e\n\u003cp\u003eLe deuxième fait intéressant ici est de voir que le niveau d\u0027éducation joue visiblement sur l\u0027appartenance à un type de salaire.\n\u003cbr  /\u003eEn effet, seulement les individus dont le \u003cstrong\u003eniveau d\u0027éducation est supérieur ou égal à 14\u003c/strong\u003e sont \u003cstrong\u003emajoritairement\u003c/strong\u003e avec des \u003cstrong\u003esalaire supérieur à 50k\u003c/strong\u003e\u003c/p\u003e\n"
      },
      "dateCreated": "Mar 7, 2017 10:46:18 AM",
      "dateStarted": "Mar 7, 2017 11:20:44 AM",
      "dateFinished": "Mar 7, 2017 11:20:44 AM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "title": "Analyse descriptive : Individus par rapport au workclass \u0026 groupe de salaire",
      "text": "%sql \r\nselect workclass, income, count(*) \r\nfrom dataset\r\ngroup by workclass, income\r\norder by workclass DESC",
      "dateUpdated": "Mar 7, 2017 12:16:10 PM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "multiBarChart",
          "height": 214.0,
          "optionOpen": false,
          "keys": [
            {
              "name": "workclass",
              "index": 0.0,
              "aggr": "sum"
            }
          ],
          "values": [
            {
              "name": "count(1)",
              "index": 2.0,
              "aggr": "sum"
            }
          ],
          "groups": [
            {
              "name": "income",
              "index": 1.0,
              "aggr": "sum"
            }
          ],
          "scatter": {
            "xAxis": {
              "name": "workclass",
              "index": 0.0,
              "aggr": "sum"
            },
            "yAxis": {
              "name": "income",
              "index": 1.0,
              "aggr": "sum"
            }
          }
        },
        "enabled": true,
        "editorMode": "ace/mode/scala",
        "title": true,
        "editorHide": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1488883582083_1342386703",
      "id": "20170307-104622_810882328",
      "result": {
        "code": "SUCCESS",
        "type": "TABLE",
        "msg": "workclass\tincome\tcount(1)\n Without-pay\t \u003c\u003d50K\t14\n State-gov\t \u003e50K\t353\n State-gov\t \u003c\u003d50K\t945\n Self-emp-not-inc\t \u003c\u003d50K\t1817\n Self-emp-not-inc\t \u003e50K\t724\n Self-emp-inc\t \u003c\u003d50K\t494\n Self-emp-inc\t \u003e50K\t622\n Private\t \u003e50K\t4963\n Private\t \u003c\u003d50K\t17733\n Never-worked\t \u003c\u003d50K\t7\n Local-gov\t \u003c\u003d50K\t1476\n Local-gov\t \u003e50K\t617\n Federal-gov\t \u003c\u003d50K\t589\n Federal-gov\t \u003e50K\t371\n ?\t \u003e50K\t191\n ?\t \u003c\u003d50K\t1645\n"
      },
      "dateCreated": "Mar 7, 2017 10:46:22 AM",
      "dateStarted": "Mar 7, 2017 12:02:18 PM",
      "dateFinished": "Mar 7, 2017 12:02:21 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "title": "Analyse descriptive : Par rapport à l\u0027occupation",
      "text": "%sql \r\nselect occupation, income, count(*) \r\nfrom dataset\r\ngroup by occupation, income\r\norder by occupation DESC",
      "dateUpdated": "Mar 7, 2017 12:08:24 PM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "multiBarChart",
          "height": 194.0,
          "optionOpen": false,
          "keys": [
            {
              "name": "occupation",
              "index": 0.0,
              "aggr": "sum"
            }
          ],
          "values": [
            {
              "name": "count(1)",
              "index": 2.0,
              "aggr": "sum"
            }
          ],
          "groups": [
            {
              "name": "income",
              "index": 1.0,
              "aggr": "sum"
            }
          ],
          "scatter": {
            "xAxis": {
              "name": "occupation",
              "index": 0.0,
              "aggr": "sum"
            },
            "yAxis": {
              "name": "income",
              "index": 1.0,
              "aggr": "sum"
            }
          }
        },
        "enabled": true,
        "editorMode": "ace/mode/scala",
        "title": true,
        "editorHide": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1488888204853_-988016080",
      "id": "20170307-120324_496167702",
      "result": {
        "code": "SUCCESS",
        "type": "TABLE",
        "msg": "occupation\tincome\tcount(1)\n Transport-moving\t \u003c\u003d50K\t1277\n Transport-moving\t \u003e50K\t320\n Tech-support\t \u003e50K\t283\n Tech-support\t \u003c\u003d50K\t645\n Sales\t \u003c\u003d50K\t2667\n Sales\t \u003e50K\t983\n Protective-serv\t \u003e50K\t211\n Protective-serv\t \u003c\u003d50K\t438\n Prof-specialty\t \u003c\u003d50K\t2281\n Prof-specialty\t \u003e50K\t1859\n Priv-house-serv\t \u003c\u003d50K\t148\n Priv-house-serv\t \u003e50K\t1\n Other-service\t \u003c\u003d50K\t3158\n Other-service\t \u003e50K\t137\n Machine-op-inspct\t \u003c\u003d50K\t1752\n Machine-op-inspct\t \u003e50K\t250\n Handlers-cleaners\t \u003c\u003d50K\t1284\n Handlers-cleaners\t \u003e50K\t86\n Farming-fishing\t \u003c\u003d50K\t879\n Farming-fishing\t \u003e50K\t115\n Exec-managerial\t \u003e50K\t1968\n Exec-managerial\t \u003c\u003d50K\t2098\n Craft-repair\t \u003e50K\t929\n Craft-repair\t \u003c\u003d50K\t3170\n Armed-Forces\t \u003c\u003d50K\t8\n Armed-Forces\t \u003e50K\t1\n Adm-clerical\t \u003c\u003d50K\t3263\n Adm-clerical\t \u003e50K\t507\n ?\t \u003e50K\t191\n ?\t \u003c\u003d50K\t1652\n"
      },
      "dateCreated": "Mar 7, 2017 12:03:24 PM",
      "dateStarted": "Mar 7, 2017 12:04:45 PM",
      "dateFinished": "Mar 7, 2017 12:04:48 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "title": "Analyse Descriptive : Explication",
      "text": "%md\n\nPlusieurs constat sont à faire ici :\n* Tout d\u0027abord, quelque soit la \"workclass\", la proportion d\u0027individus avec des salaires inférieures à 50k est toujours supérieurs.\n* Ensuite parmis les types d\u0027occupation, on constate que les catégories \"Prof-speciality\" et \"Exec-managerial\" ont les ratio les plus équilibrés \u003d\u003e **44%** de salaire au dessus de 50k pour les enseignants, **48%** pour les manageurs.\n",
      "dateUpdated": "Mar 7, 2017 12:14:49 PM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "enabled": true,
        "editorMode": "ace/mode/markdown",
        "title": true,
        "editorHide": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1488888513637_-1121479620",
      "id": "20170307-120833_217261786",
      "result": {
        "code": "SUCCESS",
        "type": "HTML",
        "msg": "\u003cp\u003ePlusieurs constat sont à faire ici :\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eTout d\u0027abord, quelque soit la \u0026ldquo;workclass\u0026rdquo;, la proportion d\u0027individus avec des salaires inférieures à 50k est toujours supérieurs.\u003c/li\u003e\n\u003cli\u003eEnsuite parmis les types d\u0027occupation, on constate que les catégories \u0026ldquo;Prof-speciality\u0026rdquo; et \u0026ldquo;Exec-managerial\u0026rdquo; ont les ratio les plus équilibrés \u003d\u003e \u003cstrong\u003e44%\u003c/strong\u003e de salaire au dessus de 50k pour les enseignants, \u003cstrong\u003e48%\u003c/strong\u003e pour les manageurs.\u003c/li\u003e\n\u003c/ul\u003e\n"
      },
      "dateCreated": "Mar 7, 2017 12:08:33 PM",
      "dateStarted": "Mar 7, 2017 12:14:47 PM",
      "dateFinished": "Mar 7, 2017 12:14:47 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "title": "Analyse Descriptive : Individus par Ethnies et type de salaire",
      "text": "%sql \r\nselect race, income, count(*) \r\nfrom dataset\r\ngroup by race, income\r\norder by race DESC",
      "dateUpdated": "Mar 7, 2017 12:26:32 PM",
      "config": {
        "colWidth": 7.0,
        "graph": {
          "mode": "multiBarChart",
          "height": 250.0,
          "optionOpen": false,
          "keys": [
            {
              "name": "race",
              "index": 0.0,
              "aggr": "sum"
            }
          ],
          "values": [
            {
              "name": "count(1)",
              "index": 2.0,
              "aggr": "sum"
            }
          ],
          "groups": [
            {
              "name": "income",
              "index": 1.0,
              "aggr": "sum"
            }
          ],
          "scatter": {
            "xAxis": {
              "name": "race",
              "index": 0.0,
              "aggr": "sum"
            },
            "yAxis": {
              "name": "income",
              "index": 1.0,
              "aggr": "sum"
            }
          }
        },
        "enabled": true,
        "editorMode": "ace/mode/scala",
        "title": true,
        "editorHide": true,
        "tableHide": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1488888918795_-1688652573",
      "id": "20170307-121518_964947874",
      "result": {
        "code": "SUCCESS",
        "type": "TABLE",
        "msg": "race\tincome\tcount(1)\n White\t \u003c\u003d50K\t20699\n White\t \u003e50K\t7117\n Other\t \u003c\u003d50K\t246\n Other\t \u003e50K\t25\n Black\t \u003e50K\t387\n Black\t \u003c\u003d50K\t2737\n Asian-Pac-Islander\t \u003e50K\t276\n Asian-Pac-Islander\t \u003c\u003d50K\t763\n Amer-Indian-Eskimo\t \u003c\u003d50K\t275\n Amer-Indian-Eskimo\t \u003e50K\t36\n"
      },
      "dateCreated": "Mar 7, 2017 12:15:18 PM",
      "dateStarted": "Mar 7, 2017 12:16:35 PM",
      "dateFinished": "Mar 7, 2017 12:16:38 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "title": "Analyse Descriptive : Par pays de naissance (sauf USA)",
      "text": "%sql \r\nselect native_country, income, count(*) \r\nfrom dataset\r\nwhere native_country NOT LIKE \u0027%United-States%\u0027\r\ngroup by native_country, income\r\norder by native_country DESC",
      "dateUpdated": "Mar 7, 2017 12:27:03 PM",
      "config": {
        "colWidth": 5.0,
        "graph": {
          "mode": "table",
          "height": 224.0,
          "optionOpen": false,
          "keys": [
            {
              "name": "native_country",
              "index": 0.0,
              "aggr": "sum"
            }
          ],
          "values": [
            {
              "name": "count(1)",
              "index": 2.0,
              "aggr": "sum"
            }
          ],
          "groups": [
            {
              "name": "income",
              "index": 1.0,
              "aggr": "sum"
            }
          ],
          "scatter": {
            "xAxis": {
              "name": "native_country",
              "index": 0.0,
              "aggr": "sum"
            },
            "yAxis": {
              "name": "income",
              "index": 1.0,
              "aggr": "sum"
            }
          }
        },
        "enabled": true,
        "editorMode": "ace/mode/scala",
        "title": true,
        "editorHide": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1488889056761_706792435",
      "id": "20170307-121736_1637349982",
      "result": {
        "code": "SUCCESS",
        "type": "TABLE",
        "msg": "native_country\tincome\tcount(1)\n Yugoslavia\t \u003c\u003d50K\t10\n Yugoslavia\t \u003e50K\t6\n Vietnam\t \u003e50K\t5\n Vietnam\t \u003c\u003d50K\t62\n Trinadad\u0026Tobago\t \u003c\u003d50K\t17\n Trinadad\u0026Tobago\t \u003e50K\t2\n Thailand\t \u003c\u003d50K\t15\n Thailand\t \u003e50K\t3\n Taiwan\t \u003c\u003d50K\t31\n Taiwan\t \u003e50K\t20\n South\t \u003c\u003d50K\t64\n South\t \u003e50K\t16\n Scotland\t \u003e50K\t3\n Scotland\t \u003c\u003d50K\t9\n Puerto-Rico\t \u003c\u003d50K\t102\n Puerto-Rico\t \u003e50K\t12\n Portugal\t \u003e50K\t4\n Portugal\t \u003c\u003d50K\t33\n Poland\t \u003e50K\t12\n Poland\t \u003c\u003d50K\t48\n Philippines\t \u003e50K\t61\n Philippines\t \u003c\u003d50K\t137\n Peru\t \u003c\u003d50K\t29\n Peru\t \u003e50K\t2\n Outlying-US(Guam-USVI-etc)\t \u003c\u003d50K\t14\n Nicaragua\t \u003e50K\t2\n Nicaragua\t \u003c\u003d50K\t32\n Mexico\t \u003c\u003d50K\t610\n Mexico\t \u003e50K\t33\n Laos\t \u003c\u003d50K\t16\n Laos\t \u003e50K\t2\n Japan\t \u003c\u003d50K\t38\n Japan\t \u003e50K\t24\n Jamaica\t \u003c\u003d50K\t71\n Jamaica\t \u003e50K\t10\n Italy\t \u003c\u003d50K\t48\n Italy\t \u003e50K\t25\n Ireland\t \u003e50K\t5\n Ireland\t \u003c\u003d50K\t19\n Iran\t \u003c\u003d50K\t25\n Iran\t \u003e50K\t18\n India\t \u003e50K\t40\n India\t \u003c\u003d50K\t60\n Hungary\t \u003c\u003d50K\t10\n Hungary\t \u003e50K\t3\n Hong\t \u003c\u003d50K\t14\n Hong\t \u003e50K\t6\n Honduras\t \u003e50K\t1\n Honduras\t \u003c\u003d50K\t12\n Holand-Netherlands\t \u003c\u003d50K\t1\n Haiti\t \u003e50K\t4\n Haiti\t \u003c\u003d50K\t40\n Guatemala\t \u003c\u003d50K\t61\n Guatemala\t \u003e50K\t3\n Greece\t \u003e50K\t8\n Greece\t \u003c\u003d50K\t21\n Germany\t \u003c\u003d50K\t93\n Germany\t \u003e50K\t44\n France\t \u003c\u003d50K\t17\n France\t \u003e50K\t12\n England\t \u003c\u003d50K\t60\n England\t \u003e50K\t30\n El-Salvador\t \u003e50K\t9\n El-Salvador\t \u003c\u003d50K\t97\n Ecuador\t \u003e50K\t4\n Ecuador\t \u003c\u003d50K\t24\n Dominican-Republic\t \u003c\u003d50K\t68\n Dominican-Republic\t \u003e50K\t2\n Cuba\t \u003c\u003d50K\t70\n Cuba\t \u003e50K\t25\n Columbia\t \u003c\u003d50K\t57\n Columbia\t \u003e50K\t2\n China\t \u003e50K\t20\n China\t \u003c\u003d50K\t55\n Canada\t \u003c\u003d50K\t82\n Canada\t \u003e50K\t39\n Cambodia\t \u003e50K\t7\n Cambodia\t \u003c\u003d50K\t12\n ?\t \u003e50K\t146\n ?\t \u003c\u003d50K\t437\n"
      },
      "dateCreated": "Mar 7, 2017 12:17:36 PM",
      "dateStarted": "Mar 7, 2017 12:24:31 PM",
      "dateFinished": "Mar 7, 2017 12:24:34 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "title": "Analyse Descriptive : Explication",
      "text": "%md\n\nL\u0027objectif ici est de trouver des disparités dans les salaires en fonction de l\u0027éthnie ainsi que du pays de naissance:\n* Concernant les pays, l\u0027ensemble des possibilités pour \"native_country\" empêche toute analyse graphique (et ce même en excluant les Etats-Unis qui écrasaient les autres variables à cause de son poid.\n* On fait donc notre observation sur l\u0027ethnie :\n\n\nEthnie|Nombre total   |% au dessus de 50k\nBlanc               27876  \u003d\u003e                **25,7%**\nNoir                 3124  \u003d\u003e               **12,3%**\nAsiatique            1039  \u003d\u003e               **26,5%**\nAmer-Indien           311  \u003d\u003e              **11,5%**\nAutre                 271  \u003d\u003e                **12,3%**\n\n",
      "dateUpdated": "Mar 7, 2017 12:39:57 PM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "enabled": true,
        "editorMode": "ace/mode/markdown",
        "title": true,
        "editorHide": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1488889517063_1935002869",
      "id": "20170307-122517_1761425912",
      "result": {
        "code": "SUCCESS",
        "type": "HTML",
        "msg": "\u003cp\u003eL\u0027objectif ici est de trouver des disparités dans les salaires en fonction de l\u0027éthnie ainsi que du pays de naissance:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eConcernant les pays, l\u0027ensemble des possibilités pour \u0026ldquo;native_country\u0026rdquo; empêche toute analyse graphique (et ce même en excluant les Etats-Unis qui écrasaient les autres variables à cause de son poid.\u003c/li\u003e\n\u003cli\u003eOn fait donc notre observation sur l\u0027ethnie :\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eEthnie|Nombre total   |% au dessus de 50k\n\u003cbr  /\u003eBlanc               27876  \u003d\u003e                \u003cstrong\u003e25,7%\u003c/strong\u003e\n\u003cbr  /\u003eNoir                 3124  \u003d\u003e               \u003cstrong\u003e12,3%\u003c/strong\u003e\n\u003cbr  /\u003eAsiatique            1039  \u003d\u003e               \u003cstrong\u003e26,5%\u003c/strong\u003e\n\u003cbr  /\u003eAmer-Indien           311  \u003d\u003e              \u003cstrong\u003e11,5%\u003c/strong\u003e\n\u003cbr  /\u003eAutre                 271  \u003d\u003e                \u003cstrong\u003e12,3%\u003c/strong\u003e\u003c/p\u003e\n"
      },
      "dateCreated": "Mar 7, 2017 12:25:17 PM",
      "dateStarted": "Mar 7, 2017 12:39:50 PM",
      "dateFinished": "Mar 7, 2017 12:39:50 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md \n\n## IV. Data preprocessing\n\nSince we are going to try algorithms like Logistic Regression, we will have to convert the categorical variables in the dataset into numeric variables. There are 2 ways we can do this.\n\n- Category Indexing. This is basically assigning a numeric value to each category from {0, 1, 2, ...numCategories-1}. This introduces an implicit ordering among your categories, and is more suitable for ordinal variables (eg: Poor: 0, Average: 1, Good: 2)\n- [One-Hot Encoding](http://spark.apache.org/docs/latest/ml-features.html#onehotencoder). This converts categories into binary vectors with at most one positive value (eg: (Blue: 1, 0, 0), (Green: 0, 1, 0), (Red: 0, 0, 1))",
      "dateUpdated": "Feb 7, 2017 12:55:41 PM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "enabled": true,
        "editorMode": "ace/mode/markdown",
        "editorHide": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1486112592655_-113447470",
      "id": "20170203-090312_1355361868",
      "result": {
        "code": "SUCCESS",
        "type": "HTML",
        "msg": "\u003ch2\u003eIV. Data preprocessing\u003c/h2\u003e\n\u003cp\u003eSince we are going to try algorithms like Logistic Regression, we will have to convert the categorical variables in the dataset into numeric variables. There are 2 ways we can do this.\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eCategory Indexing. This is basically assigning a numeric value to each category from {0, 1, 2, \u0026hellip;numCategories-1}. This introduces an implicit ordering among your categories, and is more suitable for ordinal variables (eg: Poor: 0, Average: 1, Good: 2)\u003c/li\u003e\n\u003cli\u003e\u003ca href\u003d\"http://spark.apache.org/docs/latest/ml-features.html#onehotencoder\"\u003eOne-Hot Encoding\u003c/a\u003e. This converts categories into binary vectors with at most one positive value (eg: (Blue: 1, 0, 0), (Green: 0, 1, 0), (Red: 0, 0, 1))\u003c/li\u003e\n\u003c/ul\u003e\n"
      },
      "dateCreated": "Feb 3, 2017 9:03:12 AM",
      "dateStarted": "Feb 7, 2017 12:55:42 PM",
      "dateFinished": "Feb 7, 2017 12:55:42 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "title": "One-hot encoding example",
      "text": "val names \u003d Seq(\"color\", \"index\", \"OHE_attr1\", \"OHE_attr2\", \"OHE_attr3\")\nsqlContext.createDataFrame(sc.parallelize(Seq((\"Blue\", 0, 1, 0, 0), (\"Green\", 1, 0, 1, 0), (\"Red\", 2, 0 , 0 , 1)))).toDF(names: _*).show()",
      "dateUpdated": "Feb 7, 2017 12:55:42 PM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "enabled": true,
        "editorMode": "ace/mode/markdown",
        "title": true,
        "editorHide": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1486112775316_925418888",
      "id": "20170203-090615_788237777",
      "result": {
        "code": "SUCCESS",
        "type": "TEXT",
        "msg": "\nnames: Seq[String] \u003d List(color, index, OHE_attr1, OHE_attr2, OHE_attr3)\n+-----+-----+---------+---------+---------+\n|color|index|OHE_attr1|OHE_attr2|OHE_attr3|\n+-----+-----+---------+---------+---------+\n| Blue|    0|        1|        0|        0|\n|Green|    1|        0|        1|        0|\n|  Red|    2|        0|        0|        1|\n+-----+-----+---------+---------+---------+\n\n"
      },
      "dateCreated": "Feb 3, 2017 9:06:15 AM",
      "dateStarted": "Feb 7, 2017 12:55:53 PM",
      "dateFinished": "Feb 7, 2017 12:55:55 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\n\nIn this dataset, we have ordinal variables like education (Preschool - Doctorate), and also nominal variables like relationship (Wife, Husband, Own-child, etc). For simplicity\u0027s sake, we will use One-Hot Encoding to convert all categorical variables into binary vectors. It might be possible here to improve prediction accuracy by converting each categorical column with an appropriate method.\n\nHere, we will use a combination of [StringIndexer](http://spark.apache.org/docs/latest/ml-features.html#stringindexer) and [OneHotEncoder](http://spark.apache.org/docs/latest/ml-features.html#onehotencoder) on each string column to convert the categorical variables. The `OneHotEncoder` will return a SparseVector (which means, for `(8,[4],[1.0])` that the vector has size 8, one only the 4th column contains a value which is 1.0).\n\nSince we will have many stages of feature transformations, we use an [ML Pipeline](http://spark.apache.org/docs/latest/ml-pipeline.html) to tie the stages together.  This simplifies our code. You should especially try to use [the Pipeline example](http://spark.apache.org/docs/latest/ml-pipeline.html#example-pipeline).\n\n```scala\n// Configure an ML pipeline, which consists of two stages on one column: a StringIndexer and a OneHotEncoder.\nimport org.apache.spark.ml.feature.{OneHotEncoder, StringIndexer}\nimport org.apache.spark.ml.{Pipeline, PipelineModel}\n\n// stages for column workclass\nval stringIndexer \u003d new StringIndexer()\n  .setInputCol(\"workclass\")\n  .setOutputCol(\"workclassIndex\")\nval oneHotEncoder \u003d new OneHotEncoder()\n  .setInputCol(stringIndexer.getOutputCol)\n  .setOutputCol(stringIndexer.getInputCol + \"ClassVec\")\n  \n// stage for label\nval label_stringIdx \u003d new StringIndexer()\n    .setInputCol(\"income\")\n    .setOutputCol(\"label\")\n  \nval stages \u003d  Seq(stringIndexer, oneHotEncoder) ++ Seq(label_stringIdx) // concatenate 2 sequences of stages\nval pipeline \u003d new Pipeline()\n  .setStages(stages.toArray)\n  \nval pipelineModel \u003d pipeline.fit(dataset)\npipelineModel.transform(dataset).show()\n```\n\nIt is also a good time to transform the income to a label of 0 and 1 for binary classification using the `StringIndexer`.\n\n\u003ch4 style\u003d\"color:red;\"\u003eExercise\u003c/h4\u003e\n\n1. For each categorical column, build a stage of StringIndexer and OneHotEncoder\n2. Add all those stages in a single pipeline\n3. Also add a StringIndexer of the `income` column and name the output column `label`\n3. Check the result by passing your dataset inside the pipeline. Comment \u0026 explain.\n\n_Hint: actually map your sequence of categorical columns to a sequence of stages through FP._",
      "dateUpdated": "Feb 7, 2017 12:55:42 PM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "enabled": true,
        "editorMode": "ace/mode/markdown",
        "editorHide": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1486113072470_-2067898551",
      "id": "20170203-091112_917554483",
      "result": {
        "code": "SUCCESS",
        "type": "HTML",
        "msg": "\u003cp\u003eIn this dataset, we have ordinal variables like education (Preschool - Doctorate), and also nominal variables like relationship (Wife, Husband, Own-child, etc). For simplicity\u0027s sake, we will use One-Hot Encoding to convert all categorical variables into binary vectors. It might be possible here to improve prediction accuracy by converting each categorical column with an appropriate method.\u003c/p\u003e\n\u003cp\u003eHere, we will use a combination of \u003ca href\u003d\"http://spark.apache.org/docs/latest/ml-features.html#stringindexer\"\u003eStringIndexer\u003c/a\u003e and \u003ca href\u003d\"http://spark.apache.org/docs/latest/ml-features.html#onehotencoder\"\u003eOneHotEncoder\u003c/a\u003e on each string column to convert the categorical variables. The \u003ccode\u003eOneHotEncoder\u003c/code\u003e will return a SparseVector (which means, for \u003ccode\u003e(8,[4],[1.0])\u003c/code\u003e that the vector has size 8, one only the 4th column contains a value which is 1.0).\u003c/p\u003e\n\u003cp\u003eSince we will have many stages of feature transformations, we use an \u003ca href\u003d\"http://spark.apache.org/docs/latest/ml-pipeline.html\"\u003eML Pipeline\u003c/a\u003e to tie the stages together.  This simplifies our code. You should especially try to use \u003ca href\u003d\"http://spark.apache.org/docs/latest/ml-pipeline.html#example-pipeline\"\u003ethe Pipeline example\u003c/a\u003e.\u003c/p\u003e\n\u003cpre\u003e\u003ccode class\u003d\"scala\"\u003e// Configure an ML pipeline, which consists of two stages on one column: a StringIndexer and a OneHotEncoder.\nimport org.apache.spark.ml.feature.{OneHotEncoder, StringIndexer}\nimport org.apache.spark.ml.{Pipeline, PipelineModel}\n\n// stages for column workclass\nval stringIndexer \u003d new StringIndexer()\n  .setInputCol(\"workclass\")\n  .setOutputCol(\"workclassIndex\")\nval oneHotEncoder \u003d new OneHotEncoder()\n  .setInputCol(stringIndexer.getOutputCol)\n  .setOutputCol(stringIndexer.getInputCol + \"ClassVec\")\n\n// stage for label\nval label_stringIdx \u003d new StringIndexer()\n    .setInputCol(\"income\")\n    .setOutputCol(\"label\")\n\nval stages \u003d  Seq(stringIndexer, oneHotEncoder) ++ Seq(label_stringIdx) // concatenate 2 sequences of stages\nval pipeline \u003d new Pipeline()\n  .setStages(stages.toArray)\n\nval pipelineModel \u003d pipeline.fit(dataset)\npipelineModel.transform(dataset).show()\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eIt is also a good time to transform the income to a label of 0 and 1 for binary classification using the \u003ccode\u003eStringIndexer\u003c/code\u003e.\u003c/p\u003e\n\u003ch4 style\u003d\"color:red;\"\u003eExercise\u003c/h4\u003e\n\u003col\u003e\n\u003cli\u003eFor each categorical column, build a stage of StringIndexer and OneHotEncoder\u003c/li\u003e\n\u003cli\u003eAdd all those stages in a single pipeline\u003c/li\u003e\n\u003cli\u003eAlso add a StringIndexer of the \u003ccode\u003eincome\u003c/code\u003e column and name the output column \u003ccode\u003elabel\u003c/code\u003e\u003c/li\u003e\n\u003cli\u003eCheck the result by passing your dataset inside the pipeline. Comment \u0026amp; explain.\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003e\u003cem\u003eHint: actually map your sequence of categorical columns to a sequence of stages through FP.\u003c/em\u003e\u003c/p\u003e\n"
      },
      "dateCreated": "Feb 3, 2017 9:11:12 AM",
      "dateStarted": "Feb 7, 2017 12:55:42 PM",
      "dateFinished": "Feb 7, 2017 12:55:42 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "title": "Detail columns to deal with",
      "text": "val categoricalCols \u003d Seq(\"workclass\", \"education\", \"marital_status\", \"occupation\", \"relationship\", \"race\", \"sex\", \"native_country\")\nval numericCols \u003d Seq(\"age\", \"fnlwgt\", \"education_num\", \"capital_gain\", \"capital_loss\", \"hours_per_week\")",
      "dateUpdated": "Mar 6, 2017 10:50:58 AM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "enabled": true,
        "editorMode": "ace/mode/scala",
        "title": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1486391484536_-1333067431",
      "id": "20170206-143124_969747353",
      "result": {
        "code": "SUCCESS",
        "type": "TEXT",
        "msg": "\ncategoricalCols: Seq[String] \u003d List(workclass, education, marital_status, occupation, relationship, race, sex, native_country)\n\nnumericCols: Seq[String] \u003d List(age, fnlwgt, education_num, capital_gain, capital_loss, hours_per_week)\n"
      },
      "dateCreated": "Feb 6, 2017 2:31:24 AM",
      "dateStarted": "Feb 7, 2017 12:55:53 PM",
      "dateFinished": "Feb 7, 2017 12:55:56 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\n\nTo run machine learning on a dataset, you need a column which contains a vector of all the features, and a column with the label.\n\nWe use the [VectorAssembler](http://spark.apache.org/docs/latest/ml-features.html#vectorassembler) to assemble all of our numeric columns and one-hot encoded categorical columns into one.\n\n\u003ch4 style\u003d\"color:red;\"\u003eExercise\u003c/h4\u003e\n\nAdd the `VectorAssembler` stage, which takes as input all numeric columns and one hot encoded categorical columns. The `features` column will then be created. You can comment on it.",
      "dateUpdated": "Feb 7, 2017 12:55:43 PM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "enabled": true,
        "editorMode": "ace/mode/markdown",
        "editorHide": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1486113356892_-128377178",
      "id": "20170203-091556_1786454475",
      "result": {
        "code": "SUCCESS",
        "type": "HTML",
        "msg": "\u003cp\u003eTo run machine learning on a dataset, you need a column which contains a vector of all the features, and a column with the label.\u003c/p\u003e\n\u003cp\u003eWe use the \u003ca href\u003d\"http://spark.apache.org/docs/latest/ml-features.html#vectorassembler\"\u003eVectorAssembler\u003c/a\u003e to assemble all of our numeric columns and one-hot encoded categorical columns into one.\u003c/p\u003e\n\u003ch4 style\u003d\"color:red;\"\u003eExercise\u003c/h4\u003e\n\u003cp\u003eAdd the \u003ccode\u003eVectorAssembler\u003c/code\u003e stage, which takes as input all numeric columns and one hot encoded categorical columns. The \u003ccode\u003efeatures\u003c/code\u003e column will then be created. You can comment on it.\u003c/p\u003e\n"
      },
      "dateCreated": "Feb 3, 2017 9:15:56 AM",
      "dateStarted": "Feb 7, 2017 12:55:43 PM",
      "dateFinished": "Feb 7, 2017 12:55:43 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\n\nAt this point, you should have a dataframe with a column _features_ which consists of a vector of all features in numerical form, and a column _label_ with the Income as a binary value. \n\nIt looks like this for example:\n\n```\n+----+-----------------+--------+----------+-------------+-------------------+------------------+--------------+------+-----+------------+------------+--------------+--------------+------+--------------+-----------------+--------------+-----------------+-------------------+----------------------+---------------+------------------+-----------------+--------------------+---------+-------------+--------+-------------+-------------------+----------------------+-----+--------------------+\n| age|        workclass|  fnlwgt| education|education_num|     marital_status|        occupation|  relationship|  race|  sex|capital_gain|capital_loss|hours_per_week|native_country|income|workclassIndex|workclassClassVec|educationIndex|educationClassVec|marital_statusIndex|marital_statusClassVec|occupationIndex|occupationClassVec|relationshipIndex|relationshipClassVec|raceIndex| raceClassVec|sexIndex|  sexClassVec|native_countryIndex|native_countryClassVec|label|            features|\n+----+-----------------+--------+----------+-------------+-------------------+------------------+--------------+------+-----+------------+------------+--------------+--------------+------+--------------+-----------------+--------------+-----------------+-------------------+----------------------+---------------+------------------+-----------------+--------------------+---------+-------------+--------+-------------+-------------------+----------------------+-----+--------------------+\n|39.0|        State-gov| 77516.0| Bachelors|         13.0|      Never-married|      Adm-clerical| Not-in-family| White| Male|      2174.0|         0.0|          40.0| United-States| \u003c\u003d50K|           4.0|    (8,[4],[1.0])|           2.0|   (15,[2],[1.0])|                1.0|         (6,[1],[1.0])|            3.0|    (14,[3],[1.0])|              1.0|       (5,[1],[1.0])|      0.0|(4,[0],[1.0])|     0.0|(1,[0],[1.0])|                0.0|        (41,[0],[1.0])|  0.0|(100,[4,10,24,32,...|\n```\n\n\u003chr\u003e\n\n\u003ch4 style\u003d\"color:red;\"\u003eExercise\u003c/h4\u003e\n\nRandomly split your dataset into a 70% training set and 30% test set using a Dataframe\u0027s `randomSplit` function.",
      "dateUpdated": "Feb 7, 2017 12:55:43 PM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "enabled": true,
        "editorHide": true,
        "editorMode": "ace/mode/markdown"
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1486114019412_590451428",
      "id": "20170203-092659_1906384110",
      "result": {
        "code": "SUCCESS",
        "type": "HTML",
        "msg": "\u003cp\u003eAt this point, you should have a dataframe with a column \u003cem\u003efeatures\u003c/em\u003e which consists of a vector of all features in numerical form, and a column \u003cem\u003elabel\u003c/em\u003e with the Income as a binary value.\u003c/p\u003e\n\u003cp\u003eIt looks like this for example:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e+----+-----------------+--------+----------+-------------+-------------------+------------------+--------------+------+-----+------------+------------+--------------+--------------+------+--------------+-----------------+--------------+-----------------+-------------------+----------------------+---------------+------------------+-----------------+--------------------+---------+-------------+--------+-------------+-------------------+----------------------+-----+--------------------+\n| age|        workclass|  fnlwgt| education|education_num|     marital_status|        occupation|  relationship|  race|  sex|capital_gain|capital_loss|hours_per_week|native_country|income|workclassIndex|workclassClassVec|educationIndex|educationClassVec|marital_statusIndex|marital_statusClassVec|occupationIndex|occupationClassVec|relationshipIndex|relationshipClassVec|raceIndex| raceClassVec|sexIndex|  sexClassVec|native_countryIndex|native_countryClassVec|label|            features|\n+----+-----------------+--------+----------+-------------+-------------------+------------------+--------------+------+-----+------------+------------+--------------+--------------+------+--------------+-----------------+--------------+-----------------+-------------------+----------------------+---------------+------------------+-----------------+--------------------+---------+-------------+--------+-------------+-------------------+----------------------+-----+--------------------+\n|39.0|        State-gov| 77516.0| Bachelors|         13.0|      Never-married|      Adm-clerical| Not-in-family| White| Male|      2174.0|         0.0|          40.0| United-States| \u0026lt;\u003d50K|           4.0|    (8,[4],[1.0])|           2.0|   (15,[2],[1.0])|                1.0|         (6,[1],[1.0])|            3.0|    (14,[3],[1.0])|              1.0|       (5,[1],[1.0])|      0.0|(4,[0],[1.0])|     0.0|(1,[0],[1.0])|                0.0|        (41,[0],[1.0])|  0.0|(100,[4,10,24,32,...|\n\u003c/code\u003e\u003c/pre\u003e\n\u003chr\u003e\n\u003ch4 style\u003d\"color:red;\"\u003eExercise\u003c/h4\u003e\n\u003cp\u003eRandomly split your dataset into a 70% training set and 30% test set using a Dataframe\u0027s \u003ccode\u003erandomSplit\u003c/code\u003e function.\u003c/p\u003e\n"
      },
      "dateCreated": "Feb 3, 2017 9:26:59 AM",
      "dateStarted": "Feb 7, 2017 12:55:44 PM",
      "dateFinished": "Feb 7, 2017 12:55:44 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md \n\n## V. Creation of models\n\nWe are now ready to try out some of the Binary Classification Algorithms available in the new ML Pipelines API.\n\nWe have the choice between:\n- [Binomial Logistic regression](http://spark.apache.org/docs/latest/ml-classification-regression.html#binomial-logistic-regression)\n- [Decision trees](http://spark.apache.org/docs/latest/ml-classification-regression.html#decision-trees)\n- [Random forest](http://spark.apache.org/docs/latest/ml-classification-regression.html#random-forests)\n\nThese are the general steps we will take to build our models:\n- Create the initial model on the training set\n- Use your model to make predictions on your testing set\n- Evaluate the quality of your predictions\n\nWe will be using the `BinaryClassificationEvaluator` to evaluate our models. The default metric used here is [areaUnderROC](https://en.wikipedia.org/wiki/Receiver_operating_characteristic#Area_under_the_curve).\n\n\u003ch4 style\u003d\"color:red;\"\u003eExercise\u003c/h4\u003e\n\n1. Fit your data on one of the three Machine Learning models on the training dataset. This should create an Estimator.\n2. Run the estimator on the testing dataset to create a prediction column\n3. Use `BinaryClassificationEvaluator.evaluate()` to evaluate your predictions.",
      "dateUpdated": "Feb 7, 2017 12:55:44 PM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "enabled": true,
        "editorMode": "ace/mode/markdown",
        "editorHide": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1486114303097_-616679895",
      "id": "20170203-093143_100322687",
      "result": {
        "code": "SUCCESS",
        "type": "HTML",
        "msg": "\u003ch2\u003eV. Creation of models\u003c/h2\u003e\n\u003cp\u003eWe are now ready to try out some of the Binary Classification Algorithms available in the new ML Pipelines API.\u003c/p\u003e\n\u003cp\u003eWe have the choice between:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href\u003d\"http://spark.apache.org/docs/latest/ml-classification-regression.html#binomial-logistic-regression\"\u003eBinomial Logistic regression\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href\u003d\"http://spark.apache.org/docs/latest/ml-classification-regression.html#decision-trees\"\u003eDecision trees\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href\u003d\"http://spark.apache.org/docs/latest/ml-classification-regression.html#random-forests\"\u003eRandom forest\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eThese are the general steps we will take to build our models:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eCreate the initial model on the training set\u003c/li\u003e\n\u003cli\u003eUse your model to make predictions on your testing set\u003c/li\u003e\n\u003cli\u003eEvaluate the quality of your predictions\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eWe will be using the \u003ccode\u003eBinaryClassificationEvaluator\u003c/code\u003e to evaluate our models. The default metric used here is \u003ca href\u003d\"https://en.wikipedia.org/wiki/Receiver_operating_characteristic#Area_under_the_curve\"\u003eareaUnderROC\u003c/a\u003e.\u003c/p\u003e\n\u003ch4 style\u003d\"color:red;\"\u003eExercise\u003c/h4\u003e\n\u003col\u003e\n\u003cli\u003eFit your data on one of the three Machine Learning models on the training dataset. This should create an Estimator.\u003c/li\u003e\n\u003cli\u003eRun the estimator on the testing dataset to create a prediction column\u003c/li\u003e\n\u003cli\u003eUse \u003ccode\u003eBinaryClassificationEvaluator.evaluate()\u003c/code\u003e to evaluate your predictions.\u003c/li\u003e\n\u003c/ol\u003e\n"
      },
      "dateCreated": "Feb 3, 2017 9:31:43 AM",
      "dateStarted": "Feb 7, 2017 12:55:44 PM",
      "dateFinished": "Feb 7, 2017 12:55:44 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\n\n\u003ch4 style\u003d\"color:red;\"\u003eOptional question\u003c/h4\u003e\n\nUse [cross-validation](http://spark.apache.org/docs/latest/ml-tuning.html#cross-validation) to select the best hyperparameters for your model",
      "dateUpdated": "Feb 7, 2017 12:55:44 PM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "enabled": true,
        "editorMode": "ace/mode/scala",
        "editorHide": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1486412170872_-693891339",
      "id": "20170206-201610_429327674",
      "result": {
        "code": "SUCCESS",
        "type": "HTML",
        "msg": "\u003ch4 style\u003d\"color:red;\"\u003eOptional question\u003c/h4\u003e\n\u003cp\u003eUse \u003ca href\u003d\"http://spark.apache.org/docs/latest/ml-tuning.html#cross-validation\"\u003ecross-validation\u003c/a\u003e to select the best hyperparameters for your model\u003c/p\u003e\n"
      },
      "dateCreated": "Feb 6, 2017 8:16:10 AM",
      "dateStarted": "Feb 7, 2017 12:55:45 PM",
      "dateFinished": "Feb 7, 2017 12:55:45 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\n\n\u003ch4 style\u003d\"color:red;\"\u003eOptional question\u003c/h4\u003e\n\nThe column `features` is a Vector, and Spark MLlib has specific functions to analyse it. You can `collect()` the column into an array then `map` each `Row` into a `Vector`.\n\n```\nimport org.apache.spark.mllib.linalg.Vector\n\ndf.select(\"features\").rdd.map(t \u003d\u003e t.getAs[Vector](0))\n```\n\n1. Run [basic statistics](http://spark.apache.org/docs/latest/mllib-statistics.html) on the column which contains your features vector.\n2. Check for the columns that are the most [correlated](http://spark.apache.org/docs/latest/mllib-statistics.html#correlations) to your label column.\n3. Conclude on the interesting columns to use if you had to do manual feature selection. Don\u0027t forget the nature of the data you are dealing with.",
      "dateUpdated": "Feb 7, 2017 12:55:45 PM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "enabled": true,
        "editorMode": "ace/mode/markdown",
        "editorHide": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1486114332673_-1809154654",
      "id": "20170203-093212_958935340",
      "result": {
        "code": "SUCCESS",
        "type": "HTML",
        "msg": "\u003ch4 style\u003d\"color:red;\"\u003eOptional question\u003c/h4\u003e\n\u003cp\u003eThe column \u003ccode\u003efeatures\u003c/code\u003e is a Vector, and Spark MLlib has specific functions to analyse it. You can \u003ccode\u003ecollect()\u003c/code\u003e the column into an array then \u003ccode\u003emap\u003c/code\u003e each \u003ccode\u003eRow\u003c/code\u003e into a \u003ccode\u003eVector\u003c/code\u003e.\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003eimport org.apache.spark.mllib.linalg.Vector\n\ndf.select(\"features\").rdd.map(t \u003d\u0026gt; t.getAs[Vector](0))\n\u003c/code\u003e\u003c/pre\u003e\n\u003col\u003e\n\u003cli\u003eRun \u003ca href\u003d\"http://spark.apache.org/docs/latest/mllib-statistics.html\"\u003ebasic statistics\u003c/a\u003e on the column which contains your features vector.\u003c/li\u003e\n\u003cli\u003eCheck for the columns that are the most \u003ca href\u003d\"http://spark.apache.org/docs/latest/mllib-statistics.html#correlations\"\u003ecorrelated\u003c/a\u003e to your label column.\u003c/li\u003e\n\u003cli\u003eConclude on the interesting columns to use if you had to do manual feature selection. Don\u0027t forget the nature of the data you are dealing with.\u003c/li\u003e\n\u003c/ol\u003e\n"
      },
      "dateCreated": "Feb 3, 2017 9:32:12 AM",
      "dateStarted": "Feb 7, 2017 12:55:45 PM",
      "dateFinished": "Feb 7, 2017 12:55:45 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "",
      "dateUpdated": "Feb 7, 2017 12:55:46 PM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "enabled": true,
        "editorMode": "ace/mode/scala"
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1486398557317_-983551642",
      "id": "20170206-162917_1903479723",
      "result": {
        "code": "SUCCESS",
        "type": "TEXT",
        "msg": ""
      },
      "dateCreated": "Feb 6, 2017 4:29:17 AM",
      "dateStarted": "Feb 7, 2017 12:56:52 PM",
      "dateFinished": "Feb 7, 2017 12:57:05 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    }
  ],
  "name": "BinaryClassification",
  "id": "2C76YWXDZ",
  "angularObjects": {
    "2CCNDU86T:shared_process": [],
    "2CBPQHQYT:shared_process": [],
    "2CBVBBXDF:shared_process": [],
    "2CCN1CA9Z:shared_process": [],
    "2CD7V21Y1:shared_process": [],
    "2CBBKH6SH:shared_process": [],
    "2CCD7EJKY:shared_process": [],
    "2CDJVTBT7:shared_process": [],
    "2CC1TAK3U:shared_process": [],
    "2CCFJ3TKH:shared_process": [],
    "2CDDQGE4C:shared_process": [],
    "2CAVSTB59:shared_process": [],
    "2CB5U9F3Z:shared_process": [],
    "2CB66UMJM:shared_process": [],
    "2CB1MQJT5:shared_process": [],
    "2CCQ8W36H:shared_process": [],
    "2CAF38CGM:shared_process": [],
    "2CCRWS8R1:shared_process": []
  },
  "config": {},
  "info": {}
}